{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anthropic\n",
      "Collecting anthropic\n",
      "  Downloading anthropic-0.58.2-py3-none-any.whl.metadata (27 kB)\n",
      "  Downloading anthropic-0.58.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting requests\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-dotenv\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting google-generativeai\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "  Downloading charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.176.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading google_api_python_client-2.176.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.73.1-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "  Downloading grpcio-1.73.1-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/765.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m672.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m672.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-macosx_10_12_x86_64.whl (311 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-macosx_10_12_x86_64.whl (311 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pydantic_core-2.33.2-cp313-cp313-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading anthropic-0.58.2-py3-none-any.whl (292 kB)\n",
      "Downloading anthropic-0.58.2-py3-none-any.whl (292 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl (199 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl (199 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.73.1-cp313-cp313-macosx_11_0_universal2.whl (10.6 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading grpcio-1.73.1-cp313-cp313-macosx_11_0_universal2.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading google_api_python_client-2.176.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading google_api_python_client-2.176.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: urllib3, uritemplate, typing-extensions, tqdm, sniffio, python-dotenv, pyparsing, pyasn1, protobuf, jiter, idna, h11, grpcio, distro, charset_normalizer, certifi, cachetools, annotated-types, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, httplib2, httpcore, googleapis-common-protos, anyio, pydantic, httpx, grpcio-status, google-auth, openai, google-auth-httplib2, google-api-core, anthropic, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[?25lInstalling collected packages: urllib3, uritemplate, typing-extensions, tqdm, sniffio, python-dotenv, pyparsing, pyasn1, protobuf, jiter, idna, h11, grpcio, distro, charset_normalizer, certifi, cachetools, annotated-types, typing-inspection, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, httplib2, httpcore, googleapis-common-protos, anyio, pydantic, httpx, grpcio-status, google-auth, openai, google-auth-httplib2, google-api-core, anthropic, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/39\u001b[0m [google-generativeai]ogle-generativeai]language]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anthropic-0.58.2 anyio-4.9.0 cachetools-5.5.2 certifi-2025.7.14 charset_normalizer-3.4.2 distro-1.9.0 google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.176.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.73.1 grpcio-status-1.71.2 h11-0.16.0 httpcore-1.0.9 httplib2-0.22.0 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.97.0 proto-plus-1.26.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.7 pydantic-core-2.33.2 pyparsing-3.2.3 python-dotenv-1.1.1 requests-2.32.4 rsa-4.9.1 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.14.1 typing-inspection-0.4.1 uritemplate-4.2.0 urllib3-2.5.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/39\u001b[0m [google-generativeai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anthropic-0.58.2 anyio-4.9.0 cachetools-5.5.2 certifi-2025.7.14 charset_normalizer-3.4.2 distro-1.9.0 google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.176.0 google-auth-2.40.3 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.73.1 grpcio-status-1.71.2 h11-0.16.0 httpcore-1.0.9 httplib2-0.22.0 httpx-0.28.1 idna-3.10 jiter-0.10.0 openai-1.97.0 proto-plus-1.26.1 protobuf-5.29.5 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.7 pydantic-core-2.33.2 pyparsing-3.2.3 python-dotenv-1.1.1 requests-2.32.4 rsa-4.9.1 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.14.1 typing-inspection-0.4.1 uritemplate-4.2.0 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install openai anthropic requests python-dotenv google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d759082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# You can also set API keys directly (not recommended for production)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key\"\n",
    "# os.environ[\"HUGGINGFACE_API_KEY\"] = \"your-huggingface-api-key\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145aa70",
   "metadata": {},
   "source": [
    "## 1. OpenAI API Example\n",
    "\n",
    "OpenAI provides powerful models like GPT-3.5 and GPT-4. You'll need an API key from [OpenAI Platform](https://platform.openai.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def call_openai_api(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Make a call to OpenAI's API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calling OpenAI API: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain what machine learning is in simple terms.\"\n",
    "result = call_openai_api(prompt)\n",
    "print(\"OpenAI Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd66b3e",
   "metadata": {},
   "source": [
    "## 2. Anthropic Claude API Example\n",
    "\n",
    "Anthropic provides the Claude family of models. You'll need an API key from [Anthropic Console](https://console.anthropic.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2664111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "def call_anthropic_api(prompt, model=\"claude-3-haiku-20240307\"):\n",
    "    \"\"\"\n",
    "    Make a call to Anthropic's Claude API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = anthropic.Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=150,\n",
    "            temperature=0.7,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return response.content[0].text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calling Anthropic API: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What are the benefits of renewable energy?\"\n",
    "result = call_anthropic_api(prompt)\n",
    "print(\"Anthropic Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f290913",
   "metadata": {},
   "source": [
    "## 3. Hugging Face API Example\n",
    "\n",
    "Hugging Face provides access to thousands of open-source models. Get your API key from [Hugging Face Settings](https://huggingface.co/settings/tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_huggingface_api(prompt, model=\"microsoft/DialoGPT-medium\"):\n",
    "    \"\"\"\n",
    "    Make a call to Hugging Face's Inference API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api_key = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "        headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "        \n",
    "        api_url = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "        \n",
    "        payload = {\"inputs\": prompt}\n",
    "        \n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        if isinstance(result, list) and len(result) > 0:\n",
    "            return result[0].get('generated_text', str(result))\n",
    "        return str(result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calling Hugging Face API: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "prompt = \"The future of artificial intelligence is\"\n",
    "result = call_huggingface_api(prompt)\n",
    "print(\"Hugging Face Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0300a23",
   "metadata": {},
   "source": [
    "## 4. Google Gemini API Example\n",
    "\n",
    "Google's Gemini models are available through the AI Studio. Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def call_gemini_api(prompt, model=\"gemini-pro\"):\n",
    "    \"\"\"\n",
    "    Make a call to Google's Gemini API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "        \n",
    "        model = genai.GenerativeModel(model)\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        return response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calling Gemini API: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Explain the concept of neural networks.\"\n",
    "result = call_gemini_api(prompt)\n",
    "print(\"Gemini Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933052d2",
   "metadata": {},
   "source": [
    "## 5. Local LLM APIs (Ollama Example)\n",
    "\n",
    "For local LLMs, you can use Ollama or similar tools. This doesn't require API keys but needs the model running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama_api(prompt, model=\"llama2\", base_url=\"http://localhost:11434\"):\n",
    "    \"\"\"\n",
    "    Make a call to local Ollama API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"{base_url}/api/generate\"\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        return result.get('response', str(result))\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calling Ollama API: {str(e)}\"\n",
    "\n",
    "# Example usage (requires Ollama running locally)\n",
    "prompt = \"What is the capital of France?\"\n",
    "result = call_ollama_api(prompt)\n",
    "print(\"Ollama Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d29133",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48ec7964",
   "metadata": {},
   "source": [
    "### Option 2: Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bd6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API key set!\n"
     ]
    }
   ],
   "source": [
    "# 🔑 STEP 1: Set your Gemini API key here\n",
    "# Replace \"your-gemini-api-key-here\" with your actual API key\n",
    "from config_template import GOOGLE_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "print(\"✅ Gemini API key set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd32d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def call_gemini_api(prompt, model=\"gemini-1.5-flash\"):\n",
    "    \"\"\"\n",
    "    Make a call to Google's Gemini API\n",
    "    Updated with current model names: \n",
    "    - gemini-1.5-flash (free, fast)\n",
    "    - gemini-1.5-pro (more capable)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "        \n",
    "        model = genai.GenerativeModel(model)\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        return response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error calling Gemini API: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a15139",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2465c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a **smart computer program** that can **think** and **learn** like a human (but sometimes even better at very specific tasks!).\n",
      "\n",
      "That's artificial intelligence in simple terms.\n",
      "\n",
      "It's about making computers **intelligent**, so they can:\n",
      "\n",
      "*   **Understand things** (like your voice, or pictures)\n",
      "*   **Solve problems** (like recommending a movie you'll like)\n",
      "*   **Make decisions** (like deciding the best route to take while driving)\n",
      "*   **Learn from experience** (so they get better over time, like how Netflix learns what shows you enjoy)\n",
      "\n",
      "So, it's not a robot with feelings (yet!), but a computer program that shows some form of \"smart\" behavior.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"What is artificial intelligence in simple terms?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b892d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
